{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "from suppfun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in splitted set\n",
    "traindf = pd.read_csv('Data/train_set.csv')\n",
    "valdf = pd.read_csv('Data/val_set.csv')\n",
    "testdf = pd.read_csv('Data/test_set.csv')\n",
    "#trainvaldf = pd.concat([traindf,valdf], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = pd.concat([traindf, valdf], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path\n",
    "data_path = \"./Data/all\"    \n",
    "action_name_path = \"./Data/labels.pkl\"\n",
    "save_model_path = \"./Conv3D_ckpt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN parameters\n",
    "fc_hidden1, fc_hidden2 = 200, 200\n",
    "dropout = 0.3        # dropout probability\n",
    "\n",
    "# training parameters\n",
    "k = 10            # number of target category\n",
    "epochs = 15\n",
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "log_interval = 10\n",
    "img_x, img_y = 150, 200  # resize video 2d frame size\n",
    "\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 11, 1\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    # set model as training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device).view(-1, )\n",
    "\n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)  # output size = (batch, number of classes)\n",
    "\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # to compute accuracy\n",
    "        y_pred = torch.max(output, 1)[1]  # y_pred != output\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show information\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "\n",
    "    return losses, scores\n",
    "\n",
    "\n",
    "def validation(model, device, optimizer, test_loader, epoch):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device).view(-1, )\n",
    "\n",
    "            output = model(X)\n",
    "\n",
    "            loss = F.cross_entropy(output, y, reduction='sum')\n",
    "            test_loss += loss.item()                 # sum up batch loss\n",
    "            y_pred = output.max(1, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
    "\n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # to compute accuracy\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100* test_score))\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "    torch.save(model.state_dict(), os.path.join(save_model_path, '3dcnn_epoch{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
    "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, '3dcnn_optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "    print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "    return test_loss, test_score\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Detect devices\n",
    "    use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "    # load UCF101 actions names\n",
    "    params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    # load UCF101 actions names\n",
    "    with open(action_name_path, 'rb') as f:\n",
    "        action_names = pickle.load(f)   # load UCF101 actions names\n",
    "\n",
    "    # convert labels -> category\n",
    "    le = LabelEncoder()\n",
    "    le.fit(action_names)\n",
    "\n",
    "    # show how many classes there are\n",
    "    list(le.classes_)\n",
    "\n",
    "    # convert category -> 1-hot\n",
    "    action_category = le.transform(action_names).reshape(-1, 1)\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(action_category)\n",
    "\n",
    "    # # example\n",
    "    # y = ['HorseRace', 'YoYo', 'WalkingWithDog']\n",
    "    # y_onehot = labels2onehot(enc, le, y)\n",
    "    # y2 = onehot2labels(le, y_onehot)\n",
    "\n",
    "    '''\n",
    "    train_test_split\n",
    "    '''\n",
    "\n",
    "    # #actions = []\n",
    "    # # fnames = os.listdir(data_path)\n",
    "\n",
    "    # # all_names = []\n",
    "    # # for f in fnames:\n",
    "    # #     all_names.append(f)\n",
    "\n",
    "    # # with open('Data/labels.pkl', 'rb') as ff:\n",
    "    # #     actions = pickle.load(ff)\n",
    "\n",
    "    # actions = trainvaldf['Label'].tolist()\n",
    "    # all_names = trainvaldf['Index'].tolist()\n",
    "\n",
    "    # # list all data files\n",
    "    # all_X_list = all_names              # all video file names\n",
    "    # all_y_list = labels2cat(le, actions)    # all video labels\n",
    "\n",
    "    # # train, test split\n",
    "    # train_list, test_list, train_label, test_label = train_test_split(all_X_list, all_y_list, test_size=0.1/0.9, random_state=42)\n",
    "\n",
    "\n",
    "    train_list = list(map(str,traindf['Index'].tolist()))\n",
    "    test_list = list(map(str,testdf['Index'].tolist()))\n",
    "    train_label = labels2cat(le, traindf['Label'].tolist())\n",
    "    test_label = labels2cat(le, testdf['Label'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "    # image transformation\n",
    "    transform = transforms.Compose([transforms.Resize([img_x, img_y]),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "    selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()\n",
    "\n",
    "    train_set, valid_set = Dataset_3DCNN(data_path, train_list, train_label, selected_frames, transform=transform), \\\n",
    "                           Dataset_3DCNN(data_path, test_list, test_label, selected_frames, transform=transform)\n",
    "    train_loader = data.DataLoader(train_set, **params)\n",
    "    valid_loader = data.DataLoader(valid_set, **params)\n",
    "\n",
    "    # create model\n",
    "    cnn3d = CNN3D(t_dim=len(selected_frames), img_x=img_x, img_y=img_y,\n",
    "                  drop_p=dropout, fc_hidden1=fc_hidden1,  fc_hidden2=fc_hidden2, num_classes=k).to(device)\n",
    "\n",
    "\n",
    "    # Parallelize model to multiple GPUs\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        cnn3d = nn.DataParallel(cnn3d)\n",
    "\n",
    "    optimizer = torch.optim.Adam(cnn3d.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "\n",
    "\n",
    "    # record training process\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_scores = []\n",
    "    epoch_test_losses = []\n",
    "    epoch_test_scores = []\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(epochs):\n",
    "        # train, test model\n",
    "        train_losses, train_scores = train(log_interval, cnn3d, device, train_loader, optimizer, epoch)\n",
    "        epoch_test_loss, epoch_test_score = validation(cnn3d, device, optimizer, valid_loader,epoch)\n",
    "\n",
    "        # save results\n",
    "        epoch_train_losses.append(train_losses)\n",
    "        epoch_train_scores.append(train_scores)\n",
    "        epoch_test_losses.append(epoch_test_loss)\n",
    "        epoch_test_scores.append(epoch_test_score)\n",
    "\n",
    "        # save all train test results\n",
    "        A = np.array(epoch_train_losses)\n",
    "        B = np.array(epoch_train_scores)\n",
    "        C = np.array(epoch_test_losses)\n",
    "        D = np.array(epoch_test_scores)\n",
    "        np.save('./3DCNN_epoch_training_losses.npy', A)\n",
    "        np.save('./3DCNN_epoch_training_scores.npy', B)\n",
    "        np.save('./3DCNN_epoch_test_loss.npy', C)\n",
    "        np.save('./3DCNN_epoch_test_score.npy', D)\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(np.arange(1, epochs + 1), A[:, -1])  # train loss (on epoch end)\n",
    "    plt.plot(np.arange(1, epochs + 1), C)         #  test loss (on epoch end)\n",
    "    plt.title(\"model loss\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "    # 2nd figure\n",
    "    plt.subplot(122)\n",
    "    plt.plot(np.arange(1, epochs + 1), B[:, -1])  # train accuracy (on epoch end)\n",
    "    plt.plot(np.arange(1, epochs + 1), D)         #  test accuracy (on epoch end)\n",
    "    # plt.plot(histories.losses_val)\n",
    "    plt.title(\"training scores\")\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "    title = \"./fig_JESTER_3DCNN.png\"\n",
    "    plt.savefig(title, dpi=600)\n",
    "    # plt.close(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [320/12702 (3%)]\tLoss: 2.341805, Accu: 12.50%\n",
      "Train Epoch: 1 [640/12702 (5%)]\tLoss: 2.343843, Accu: 6.25%\n",
      "Train Epoch: 1 [960/12702 (8%)]\tLoss: 2.369688, Accu: 9.38%\n",
      "Train Epoch: 1 [1280/12702 (10%)]\tLoss: 2.269604, Accu: 15.62%\n",
      "Train Epoch: 1 [1600/12702 (13%)]\tLoss: 2.331365, Accu: 6.25%\n",
      "Train Epoch: 1 [1920/12702 (15%)]\tLoss: 2.297497, Accu: 12.50%\n",
      "Train Epoch: 1 [2240/12702 (18%)]\tLoss: 2.352239, Accu: 6.25%\n",
      "Train Epoch: 1 [2560/12702 (20%)]\tLoss: 2.315381, Accu: 9.38%\n",
      "Train Epoch: 1 [2880/12702 (23%)]\tLoss: 2.329042, Accu: 6.25%\n",
      "Train Epoch: 1 [3200/12702 (25%)]\tLoss: 2.285373, Accu: 18.75%\n",
      "Train Epoch: 1 [3520/12702 (28%)]\tLoss: 2.307982, Accu: 15.62%\n",
      "Train Epoch: 1 [3840/12702 (30%)]\tLoss: 2.358641, Accu: 12.50%\n",
      "Train Epoch: 1 [4160/12702 (33%)]\tLoss: 2.288486, Accu: 6.25%\n",
      "Train Epoch: 1 [4480/12702 (35%)]\tLoss: 2.309194, Accu: 15.62%\n",
      "Train Epoch: 1 [4800/12702 (38%)]\tLoss: 2.300680, Accu: 6.25%\n",
      "Train Epoch: 1 [5120/12702 (40%)]\tLoss: 2.362399, Accu: 12.50%\n",
      "Train Epoch: 1 [5440/12702 (43%)]\tLoss: 2.309214, Accu: 9.38%\n",
      "Train Epoch: 1 [5760/12702 (45%)]\tLoss: 2.296968, Accu: 15.62%\n",
      "Train Epoch: 1 [6080/12702 (48%)]\tLoss: 2.314157, Accu: 6.25%\n",
      "Train Epoch: 1 [6400/12702 (50%)]\tLoss: 2.303082, Accu: 12.50%\n",
      "Train Epoch: 1 [6720/12702 (53%)]\tLoss: 2.319186, Accu: 6.25%\n",
      "Train Epoch: 1 [7040/12702 (55%)]\tLoss: 2.298970, Accu: 9.38%\n",
      "Train Epoch: 1 [7360/12702 (58%)]\tLoss: 2.341775, Accu: 3.12%\n",
      "Train Epoch: 1 [7680/12702 (60%)]\tLoss: 2.334405, Accu: 12.50%\n",
      "Train Epoch: 1 [8000/12702 (63%)]\tLoss: 2.320302, Accu: 12.50%\n",
      "Train Epoch: 1 [8320/12702 (65%)]\tLoss: 2.302226, Accu: 9.38%\n",
      "Train Epoch: 1 [8640/12702 (68%)]\tLoss: 2.291133, Accu: 9.38%\n",
      "Train Epoch: 1 [8960/12702 (71%)]\tLoss: 2.290476, Accu: 12.50%\n",
      "Train Epoch: 1 [9280/12702 (73%)]\tLoss: 2.307459, Accu: 18.75%\n",
      "Train Epoch: 1 [9600/12702 (76%)]\tLoss: 2.313333, Accu: 15.62%\n",
      "Train Epoch: 1 [9920/12702 (78%)]\tLoss: 2.290279, Accu: 18.75%\n",
      "Train Epoch: 1 [10240/12702 (81%)]\tLoss: 2.327124, Accu: 9.38%\n",
      "Train Epoch: 1 [10560/12702 (83%)]\tLoss: 2.308385, Accu: 6.25%\n",
      "Train Epoch: 1 [10880/12702 (86%)]\tLoss: 2.292934, Accu: 15.62%\n",
      "Train Epoch: 1 [11200/12702 (88%)]\tLoss: 2.298102, Accu: 12.50%\n",
      "Train Epoch: 1 [11520/12702 (91%)]\tLoss: 2.291076, Accu: 12.50%\n",
      "Train Epoch: 1 [11840/12702 (93%)]\tLoss: 2.310451, Accu: 9.38%\n",
      "Train Epoch: 1 [12160/12702 (96%)]\tLoss: 2.317034, Accu: 0.00%\n",
      "Train Epoch: 1 [12480/12702 (98%)]\tLoss: 2.302537, Accu: 6.25%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.3029, Accuracy: 10.35%\n",
      "\n",
      "Epoch 1 model saved!\n",
      "Train Epoch: 2 [320/12702 (3%)]\tLoss: 2.302468, Accu: 12.50%\n",
      "Train Epoch: 2 [640/12702 (5%)]\tLoss: 2.310126, Accu: 12.50%\n",
      "Train Epoch: 2 [960/12702 (8%)]\tLoss: 2.306870, Accu: 9.38%\n",
      "Train Epoch: 2 [1280/12702 (10%)]\tLoss: 2.295784, Accu: 6.25%\n",
      "Train Epoch: 2 [1600/12702 (13%)]\tLoss: 2.297486, Accu: 18.75%\n",
      "Train Epoch: 2 [1920/12702 (15%)]\tLoss: 2.300452, Accu: 3.12%\n",
      "Train Epoch: 2 [2240/12702 (18%)]\tLoss: 2.271079, Accu: 18.75%\n",
      "Train Epoch: 2 [2560/12702 (20%)]\tLoss: 2.327687, Accu: 18.75%\n",
      "Train Epoch: 2 [2880/12702 (23%)]\tLoss: 2.311269, Accu: 12.50%\n",
      "Train Epoch: 2 [3200/12702 (25%)]\tLoss: 2.308478, Accu: 15.62%\n",
      "Train Epoch: 2 [3520/12702 (28%)]\tLoss: 2.301074, Accu: 9.38%\n",
      "Train Epoch: 2 [3840/12702 (30%)]\tLoss: 2.298091, Accu: 9.38%\n",
      "Train Epoch: 2 [4160/12702 (33%)]\tLoss: 2.301271, Accu: 15.62%\n",
      "Train Epoch: 2 [4480/12702 (35%)]\tLoss: 2.287621, Accu: 25.00%\n",
      "Train Epoch: 2 [4800/12702 (38%)]\tLoss: 2.303513, Accu: 12.50%\n",
      "Train Epoch: 2 [5120/12702 (40%)]\tLoss: 2.307370, Accu: 12.50%\n",
      "Train Epoch: 2 [5440/12702 (43%)]\tLoss: 2.295944, Accu: 12.50%\n",
      "Train Epoch: 2 [5760/12702 (45%)]\tLoss: 2.303267, Accu: 9.38%\n",
      "Train Epoch: 2 [6080/12702 (48%)]\tLoss: 2.310001, Accu: 9.38%\n",
      "Train Epoch: 2 [6400/12702 (50%)]\tLoss: 2.299310, Accu: 15.62%\n",
      "Train Epoch: 2 [6720/12702 (53%)]\tLoss: 2.304225, Accu: 12.50%\n",
      "Train Epoch: 2 [7040/12702 (55%)]\tLoss: 2.309112, Accu: 9.38%\n",
      "Train Epoch: 2 [7360/12702 (58%)]\tLoss: 2.302538, Accu: 6.25%\n",
      "Train Epoch: 2 [7680/12702 (60%)]\tLoss: 2.302120, Accu: 6.25%\n",
      "Train Epoch: 2 [8000/12702 (63%)]\tLoss: 2.309677, Accu: 0.00%\n",
      "Train Epoch: 2 [8320/12702 (65%)]\tLoss: 2.300571, Accu: 12.50%\n",
      "Train Epoch: 2 [8640/12702 (68%)]\tLoss: 2.307962, Accu: 15.62%\n",
      "Train Epoch: 2 [8960/12702 (71%)]\tLoss: 2.299054, Accu: 12.50%\n",
      "Train Epoch: 2 [9280/12702 (73%)]\tLoss: 2.298186, Accu: 12.50%\n",
      "Train Epoch: 2 [9600/12702 (76%)]\tLoss: 2.294545, Accu: 21.88%\n",
      "Train Epoch: 2 [9920/12702 (78%)]\tLoss: 2.295195, Accu: 12.50%\n",
      "Train Epoch: 2 [10240/12702 (81%)]\tLoss: 2.307772, Accu: 9.38%\n",
      "Train Epoch: 2 [10560/12702 (83%)]\tLoss: 2.299754, Accu: 15.62%\n",
      "Train Epoch: 2 [10880/12702 (86%)]\tLoss: 2.309139, Accu: 3.12%\n",
      "Train Epoch: 2 [11200/12702 (88%)]\tLoss: 2.298024, Accu: 6.25%\n",
      "Train Epoch: 2 [11520/12702 (91%)]\tLoss: 2.300414, Accu: 9.38%\n",
      "Train Epoch: 2 [11840/12702 (93%)]\tLoss: 2.309038, Accu: 3.12%\n",
      "Train Epoch: 2 [12160/12702 (96%)]\tLoss: 2.298115, Accu: 9.38%\n",
      "Train Epoch: 2 [12480/12702 (98%)]\tLoss: 2.294684, Accu: 9.38%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.2986, Accuracy: 10.99%\n",
      "\n",
      "Epoch 2 model saved!\n",
      "Train Epoch: 3 [320/12702 (3%)]\tLoss: 2.329533, Accu: 12.50%\n",
      "Train Epoch: 3 [640/12702 (5%)]\tLoss: 2.347975, Accu: 12.50%\n",
      "Train Epoch: 3 [960/12702 (8%)]\tLoss: 2.296107, Accu: 25.00%\n",
      "Train Epoch: 3 [1280/12702 (10%)]\tLoss: 2.299829, Accu: 6.25%\n",
      "Train Epoch: 3 [1600/12702 (13%)]\tLoss: 2.301795, Accu: 9.38%\n",
      "Train Epoch: 3 [1920/12702 (15%)]\tLoss: 2.322396, Accu: 9.38%\n",
      "Train Epoch: 3 [2240/12702 (18%)]\tLoss: 2.304865, Accu: 0.00%\n",
      "Train Epoch: 3 [2560/12702 (20%)]\tLoss: 2.306635, Accu: 12.50%\n",
      "Train Epoch: 3 [2880/12702 (23%)]\tLoss: 2.296761, Accu: 18.75%\n",
      "Train Epoch: 3 [3200/12702 (25%)]\tLoss: 2.300643, Accu: 15.62%\n",
      "Train Epoch: 3 [3520/12702 (28%)]\tLoss: 2.294884, Accu: 3.12%\n",
      "Train Epoch: 3 [3840/12702 (30%)]\tLoss: 2.283986, Accu: 9.38%\n",
      "Train Epoch: 3 [4160/12702 (33%)]\tLoss: 2.311993, Accu: 3.12%\n",
      "Train Epoch: 3 [4480/12702 (35%)]\tLoss: 2.304851, Accu: 6.25%\n",
      "Train Epoch: 3 [4800/12702 (38%)]\tLoss: 2.297000, Accu: 18.75%\n",
      "Train Epoch: 3 [5120/12702 (40%)]\tLoss: 2.299458, Accu: 12.50%\n",
      "Train Epoch: 3 [5440/12702 (43%)]\tLoss: 2.302083, Accu: 15.62%\n",
      "Train Epoch: 3 [5760/12702 (45%)]\tLoss: 2.304806, Accu: 15.62%\n",
      "Train Epoch: 3 [6080/12702 (48%)]\tLoss: 2.275360, Accu: 15.62%\n",
      "Train Epoch: 3 [6400/12702 (50%)]\tLoss: 2.304302, Accu: 15.62%\n",
      "Train Epoch: 3 [6720/12702 (53%)]\tLoss: 2.327947, Accu: 6.25%\n",
      "Train Epoch: 3 [7040/12702 (55%)]\tLoss: 2.285975, Accu: 15.62%\n",
      "Train Epoch: 3 [7360/12702 (58%)]\tLoss: 2.295432, Accu: 12.50%\n",
      "Train Epoch: 3 [7680/12702 (60%)]\tLoss: 2.262312, Accu: 6.25%\n",
      "Train Epoch: 3 [8000/12702 (63%)]\tLoss: 2.193263, Accu: 28.12%\n",
      "Train Epoch: 3 [8320/12702 (65%)]\tLoss: 2.258538, Accu: 21.88%\n",
      "Train Epoch: 3 [8640/12702 (68%)]\tLoss: 2.279034, Accu: 12.50%\n",
      "Train Epoch: 3 [8960/12702 (71%)]\tLoss: 2.297477, Accu: 9.38%\n",
      "Train Epoch: 3 [9280/12702 (73%)]\tLoss: 2.286734, Accu: 15.62%\n",
      "Train Epoch: 3 [9600/12702 (76%)]\tLoss: 2.324949, Accu: 6.25%\n",
      "Train Epoch: 3 [9920/12702 (78%)]\tLoss: 2.281827, Accu: 18.75%\n",
      "Train Epoch: 3 [10240/12702 (81%)]\tLoss: 2.332335, Accu: 9.38%\n",
      "Train Epoch: 3 [10560/12702 (83%)]\tLoss: 2.272760, Accu: 18.75%\n",
      "Train Epoch: 3 [10880/12702 (86%)]\tLoss: 2.265093, Accu: 12.50%\n",
      "Train Epoch: 3 [11200/12702 (88%)]\tLoss: 2.327164, Accu: 15.62%\n",
      "Train Epoch: 3 [11520/12702 (91%)]\tLoss: 2.305706, Accu: 18.75%\n",
      "Train Epoch: 3 [11840/12702 (93%)]\tLoss: 2.313619, Accu: 6.25%\n",
      "Train Epoch: 3 [12160/12702 (96%)]\tLoss: 2.305754, Accu: 9.38%\n",
      "Train Epoch: 3 [12480/12702 (98%)]\tLoss: 2.280110, Accu: 12.50%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.2780, Accuracy: 11.91%\n",
      "\n",
      "Epoch 3 model saved!\n",
      "Train Epoch: 4 [320/12702 (3%)]\tLoss: 2.208711, Accu: 15.62%\n",
      "Train Epoch: 4 [640/12702 (5%)]\tLoss: 2.278834, Accu: 9.38%\n",
      "Train Epoch: 4 [960/12702 (8%)]\tLoss: 2.305725, Accu: 6.25%\n",
      "Train Epoch: 4 [1280/12702 (10%)]\tLoss: 2.269222, Accu: 6.25%\n",
      "Train Epoch: 4 [1600/12702 (13%)]\tLoss: 2.269204, Accu: 21.88%\n",
      "Train Epoch: 4 [1920/12702 (15%)]\tLoss: 2.289504, Accu: 12.50%\n",
      "Train Epoch: 4 [2240/12702 (18%)]\tLoss: 2.316283, Accu: 21.88%\n",
      "Train Epoch: 4 [2560/12702 (20%)]\tLoss: 2.282347, Accu: 15.62%\n",
      "Train Epoch: 4 [2880/12702 (23%)]\tLoss: 2.381482, Accu: 3.12%\n",
      "Train Epoch: 4 [3200/12702 (25%)]\tLoss: 2.188821, Accu: 18.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [3520/12702 (28%)]\tLoss: 2.272474, Accu: 15.62%\n",
      "Train Epoch: 4 [3840/12702 (30%)]\tLoss: 2.303039, Accu: 6.25%\n",
      "Train Epoch: 4 [4160/12702 (33%)]\tLoss: 2.282720, Accu: 12.50%\n",
      "Train Epoch: 4 [4480/12702 (35%)]\tLoss: 2.289447, Accu: 12.50%\n",
      "Train Epoch: 4 [4800/12702 (38%)]\tLoss: 2.225366, Accu: 25.00%\n",
      "Train Epoch: 4 [5120/12702 (40%)]\tLoss: 2.261981, Accu: 21.88%\n",
      "Train Epoch: 4 [5440/12702 (43%)]\tLoss: 2.245713, Accu: 18.75%\n",
      "Train Epoch: 4 [5760/12702 (45%)]\tLoss: 2.309888, Accu: 15.62%\n",
      "Train Epoch: 4 [6080/12702 (48%)]\tLoss: 2.324617, Accu: 3.12%\n",
      "Train Epoch: 4 [6400/12702 (50%)]\tLoss: 2.215560, Accu: 21.88%\n",
      "Train Epoch: 4 [6720/12702 (53%)]\tLoss: 2.324047, Accu: 12.50%\n",
      "Train Epoch: 4 [7040/12702 (55%)]\tLoss: 2.289526, Accu: 6.25%\n",
      "Train Epoch: 4 [7360/12702 (58%)]\tLoss: 2.314249, Accu: 3.12%\n",
      "Train Epoch: 4 [7680/12702 (60%)]\tLoss: 2.248768, Accu: 9.38%\n",
      "Train Epoch: 4 [8000/12702 (63%)]\tLoss: 2.330071, Accu: 15.62%\n",
      "Train Epoch: 4 [8320/12702 (65%)]\tLoss: 2.244132, Accu: 15.62%\n",
      "Train Epoch: 4 [8640/12702 (68%)]\tLoss: 2.185762, Accu: 21.88%\n",
      "Train Epoch: 4 [8960/12702 (71%)]\tLoss: 2.274779, Accu: 9.38%\n",
      "Train Epoch: 4 [9280/12702 (73%)]\tLoss: 2.282835, Accu: 15.62%\n",
      "Train Epoch: 4 [9600/12702 (76%)]\tLoss: 2.243436, Accu: 12.50%\n",
      "Train Epoch: 4 [9920/12702 (78%)]\tLoss: 2.464410, Accu: 9.38%\n",
      "Train Epoch: 4 [10240/12702 (81%)]\tLoss: 2.292207, Accu: 21.88%\n",
      "Train Epoch: 4 [10560/12702 (83%)]\tLoss: 2.142076, Accu: 25.00%\n",
      "Train Epoch: 4 [10880/12702 (86%)]\tLoss: 2.076673, Accu: 25.00%\n",
      "Train Epoch: 4 [11200/12702 (88%)]\tLoss: 2.221223, Accu: 21.88%\n",
      "Train Epoch: 4 [11520/12702 (91%)]\tLoss: 2.263896, Accu: 9.38%\n",
      "Train Epoch: 4 [11840/12702 (93%)]\tLoss: 2.408927, Accu: 18.75%\n",
      "Train Epoch: 4 [12160/12702 (96%)]\tLoss: 2.313610, Accu: 15.62%\n",
      "Train Epoch: 4 [12480/12702 (98%)]\tLoss: 2.207424, Accu: 6.25%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.1936, Accuracy: 19.35%\n",
      "\n",
      "Epoch 4 model saved!\n",
      "Train Epoch: 5 [320/12702 (3%)]\tLoss: 2.192900, Accu: 15.62%\n",
      "Train Epoch: 5 [640/12702 (5%)]\tLoss: 2.322479, Accu: 9.38%\n",
      "Train Epoch: 5 [960/12702 (8%)]\tLoss: 2.242990, Accu: 9.38%\n",
      "Train Epoch: 5 [1280/12702 (10%)]\tLoss: 2.111332, Accu: 15.62%\n",
      "Train Epoch: 5 [1600/12702 (13%)]\tLoss: 2.295117, Accu: 15.62%\n",
      "Train Epoch: 5 [1920/12702 (15%)]\tLoss: 2.300666, Accu: 15.62%\n",
      "Train Epoch: 5 [2240/12702 (18%)]\tLoss: 2.661681, Accu: 18.75%\n",
      "Train Epoch: 5 [2560/12702 (20%)]\tLoss: 2.295121, Accu: 15.62%\n",
      "Train Epoch: 5 [2880/12702 (23%)]\tLoss: 2.167250, Accu: 18.75%\n",
      "Train Epoch: 5 [3200/12702 (25%)]\tLoss: 2.176836, Accu: 18.75%\n",
      "Train Epoch: 5 [3520/12702 (28%)]\tLoss: 2.125842, Accu: 21.88%\n",
      "Train Epoch: 5 [3840/12702 (30%)]\tLoss: 2.150539, Accu: 15.62%\n",
      "Train Epoch: 5 [4160/12702 (33%)]\tLoss: 2.294237, Accu: 18.75%\n",
      "Train Epoch: 5 [4480/12702 (35%)]\tLoss: 2.344964, Accu: 12.50%\n",
      "Train Epoch: 5 [4800/12702 (38%)]\tLoss: 2.325061, Accu: 9.38%\n",
      "Train Epoch: 5 [5120/12702 (40%)]\tLoss: 2.175069, Accu: 18.75%\n",
      "Train Epoch: 5 [5440/12702 (43%)]\tLoss: 2.254201, Accu: 18.75%\n",
      "Train Epoch: 5 [5760/12702 (45%)]\tLoss: 2.171202, Accu: 12.50%\n",
      "Train Epoch: 5 [6080/12702 (48%)]\tLoss: 2.297409, Accu: 15.62%\n",
      "Train Epoch: 5 [6400/12702 (50%)]\tLoss: 2.154981, Accu: 25.00%\n",
      "Train Epoch: 5 [6720/12702 (53%)]\tLoss: 2.237283, Accu: 28.12%\n",
      "Train Epoch: 5 [7040/12702 (55%)]\tLoss: 2.287804, Accu: 15.62%\n",
      "Train Epoch: 5 [7360/12702 (58%)]\tLoss: 2.130270, Accu: 21.88%\n",
      "Train Epoch: 5 [7680/12702 (60%)]\tLoss: 2.200985, Accu: 15.62%\n",
      "Train Epoch: 5 [8000/12702 (63%)]\tLoss: 2.295045, Accu: 9.38%\n",
      "Train Epoch: 5 [8320/12702 (65%)]\tLoss: 2.218791, Accu: 15.62%\n",
      "Train Epoch: 5 [8640/12702 (68%)]\tLoss: 2.158858, Accu: 21.88%\n",
      "Train Epoch: 5 [8960/12702 (71%)]\tLoss: 1.963530, Accu: 40.62%\n",
      "Train Epoch: 5 [9280/12702 (73%)]\tLoss: 1.994810, Accu: 34.38%\n",
      "Train Epoch: 5 [9600/12702 (76%)]\tLoss: 2.158228, Accu: 18.75%\n",
      "Train Epoch: 5 [9920/12702 (78%)]\tLoss: 2.081197, Accu: 25.00%\n",
      "Train Epoch: 5 [10240/12702 (81%)]\tLoss: 2.102901, Accu: 21.88%\n",
      "Train Epoch: 5 [10560/12702 (83%)]\tLoss: 2.220787, Accu: 34.38%\n",
      "Train Epoch: 5 [10880/12702 (86%)]\tLoss: 2.173125, Accu: 31.25%\n",
      "Train Epoch: 5 [11200/12702 (88%)]\tLoss: 1.994594, Accu: 21.88%\n",
      "Train Epoch: 5 [11520/12702 (91%)]\tLoss: 2.066471, Accu: 21.88%\n",
      "Train Epoch: 5 [11840/12702 (93%)]\tLoss: 2.227260, Accu: 15.62%\n",
      "Train Epoch: 5 [12160/12702 (96%)]\tLoss: 1.805292, Accu: 50.00%\n",
      "Train Epoch: 5 [12480/12702 (98%)]\tLoss: 2.074985, Accu: 28.12%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.0516, Accuracy: 28.77%\n",
      "\n",
      "Epoch 5 model saved!\n",
      "Train Epoch: 6 [320/12702 (3%)]\tLoss: 2.175580, Accu: 21.88%\n",
      "Train Epoch: 6 [640/12702 (5%)]\tLoss: 1.994402, Accu: 31.25%\n",
      "Train Epoch: 6 [960/12702 (8%)]\tLoss: 2.091809, Accu: 34.38%\n",
      "Train Epoch: 6 [1280/12702 (10%)]\tLoss: 2.240367, Accu: 21.88%\n",
      "Train Epoch: 6 [1600/12702 (13%)]\tLoss: 2.065203, Accu: 18.75%\n",
      "Train Epoch: 6 [1920/12702 (15%)]\tLoss: 2.017830, Accu: 34.38%\n",
      "Train Epoch: 6 [2240/12702 (18%)]\tLoss: 2.020691, Accu: 28.12%\n",
      "Train Epoch: 6 [2560/12702 (20%)]\tLoss: 2.167071, Accu: 21.88%\n",
      "Train Epoch: 6 [2880/12702 (23%)]\tLoss: 2.136457, Accu: 18.75%\n",
      "Train Epoch: 6 [3200/12702 (25%)]\tLoss: 2.038485, Accu: 34.38%\n",
      "Train Epoch: 6 [3520/12702 (28%)]\tLoss: 2.388717, Accu: 21.88%\n",
      "Train Epoch: 6 [3840/12702 (30%)]\tLoss: 2.119020, Accu: 12.50%\n",
      "Train Epoch: 6 [4160/12702 (33%)]\tLoss: 1.966703, Accu: 21.88%\n",
      "Train Epoch: 6 [4480/12702 (35%)]\tLoss: 1.874021, Accu: 37.50%\n",
      "Train Epoch: 6 [4800/12702 (38%)]\tLoss: 2.026464, Accu: 28.12%\n",
      "Train Epoch: 6 [5120/12702 (40%)]\tLoss: 2.011995, Accu: 31.25%\n",
      "Train Epoch: 6 [5440/12702 (43%)]\tLoss: 2.246238, Accu: 12.50%\n",
      "Train Epoch: 6 [5760/12702 (45%)]\tLoss: 2.021707, Accu: 31.25%\n",
      "Train Epoch: 6 [6080/12702 (48%)]\tLoss: 2.040644, Accu: 34.38%\n",
      "Train Epoch: 6 [6400/12702 (50%)]\tLoss: 2.047197, Accu: 25.00%\n",
      "Train Epoch: 6 [6720/12702 (53%)]\tLoss: 1.962176, Accu: 25.00%\n",
      "Train Epoch: 6 [7040/12702 (55%)]\tLoss: 2.154413, Accu: 25.00%\n",
      "Train Epoch: 6 [7360/12702 (58%)]\tLoss: 2.145184, Accu: 25.00%\n",
      "Train Epoch: 6 [7680/12702 (60%)]\tLoss: 1.948914, Accu: 34.38%\n",
      "Train Epoch: 6 [8000/12702 (63%)]\tLoss: 2.073056, Accu: 15.62%\n",
      "Train Epoch: 6 [8320/12702 (65%)]\tLoss: 1.841222, Accu: 31.25%\n",
      "Train Epoch: 6 [8640/12702 (68%)]\tLoss: 2.080275, Accu: 25.00%\n",
      "Train Epoch: 6 [8960/12702 (71%)]\tLoss: 1.882797, Accu: 34.38%\n",
      "Train Epoch: 6 [9280/12702 (73%)]\tLoss: 2.153869, Accu: 37.50%\n",
      "Train Epoch: 6 [9600/12702 (76%)]\tLoss: 2.152544, Accu: 31.25%\n",
      "Train Epoch: 6 [9920/12702 (78%)]\tLoss: 2.156385, Accu: 18.75%\n",
      "Train Epoch: 6 [10240/12702 (81%)]\tLoss: 2.050378, Accu: 37.50%\n",
      "Train Epoch: 6 [10560/12702 (83%)]\tLoss: 1.783267, Accu: 50.00%\n",
      "Train Epoch: 6 [10880/12702 (86%)]\tLoss: 1.974421, Accu: 37.50%\n",
      "Train Epoch: 6 [11200/12702 (88%)]\tLoss: 2.060349, Accu: 34.38%\n",
      "Train Epoch: 6 [11520/12702 (91%)]\tLoss: 1.789001, Accu: 31.25%\n",
      "Train Epoch: 6 [11840/12702 (93%)]\tLoss: 1.909231, Accu: 34.38%\n",
      "Train Epoch: 6 [12160/12702 (96%)]\tLoss: 1.800938, Accu: 46.88%\n",
      "Train Epoch: 6 [12480/12702 (98%)]\tLoss: 1.868697, Accu: 31.25%\n",
      "\n",
      "Test set (1411 samples): Average loss: 1.9800, Accuracy: 32.32%\n",
      "\n",
      "Epoch 6 model saved!\n",
      "Train Epoch: 7 [320/12702 (3%)]\tLoss: 2.044021, Accu: 31.25%\n",
      "Train Epoch: 7 [640/12702 (5%)]\tLoss: 2.151050, Accu: 18.75%\n",
      "Train Epoch: 7 [960/12702 (8%)]\tLoss: 2.160062, Accu: 18.75%\n",
      "Train Epoch: 7 [1280/12702 (10%)]\tLoss: 1.842753, Accu: 34.38%\n",
      "Train Epoch: 7 [1600/12702 (13%)]\tLoss: 1.999887, Accu: 28.12%\n",
      "Train Epoch: 7 [1920/12702 (15%)]\tLoss: 2.117875, Accu: 25.00%\n",
      "Train Epoch: 7 [2240/12702 (18%)]\tLoss: 2.048209, Accu: 28.12%\n",
      "Train Epoch: 7 [2560/12702 (20%)]\tLoss: 1.780592, Accu: 50.00%\n",
      "Train Epoch: 7 [2880/12702 (23%)]\tLoss: 1.936096, Accu: 31.25%\n",
      "Train Epoch: 7 [3200/12702 (25%)]\tLoss: 2.012741, Accu: 28.12%\n",
      "Train Epoch: 7 [3520/12702 (28%)]\tLoss: 1.979015, Accu: 31.25%\n",
      "Train Epoch: 7 [3840/12702 (30%)]\tLoss: 1.975946, Accu: 21.88%\n",
      "Train Epoch: 7 [4160/12702 (33%)]\tLoss: 2.178759, Accu: 28.12%\n",
      "Train Epoch: 7 [4480/12702 (35%)]\tLoss: 1.794626, Accu: 46.88%\n",
      "Train Epoch: 7 [4800/12702 (38%)]\tLoss: 2.051954, Accu: 34.38%\n",
      "Train Epoch: 7 [5120/12702 (40%)]\tLoss: 2.318376, Accu: 21.88%\n",
      "Train Epoch: 7 [5440/12702 (43%)]\tLoss: 1.796259, Accu: 43.75%\n",
      "Train Epoch: 7 [5760/12702 (45%)]\tLoss: 2.209596, Accu: 31.25%\n",
      "Train Epoch: 7 [6080/12702 (48%)]\tLoss: 2.098694, Accu: 25.00%\n",
      "Train Epoch: 7 [6400/12702 (50%)]\tLoss: 2.173434, Accu: 21.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [6720/12702 (53%)]\tLoss: 1.947954, Accu: 37.50%\n",
      "Train Epoch: 7 [7040/12702 (55%)]\tLoss: 2.099694, Accu: 25.00%\n",
      "Train Epoch: 7 [7360/12702 (58%)]\tLoss: 2.019483, Accu: 25.00%\n",
      "Train Epoch: 7 [7680/12702 (60%)]\tLoss: 1.569023, Accu: 50.00%\n",
      "Train Epoch: 7 [8000/12702 (63%)]\tLoss: 2.120740, Accu: 25.00%\n",
      "Train Epoch: 7 [8320/12702 (65%)]\tLoss: 2.046421, Accu: 28.12%\n",
      "Train Epoch: 7 [8640/12702 (68%)]\tLoss: 1.986940, Accu: 28.12%\n",
      "Train Epoch: 7 [8960/12702 (71%)]\tLoss: 1.981984, Accu: 34.38%\n",
      "Train Epoch: 7 [9280/12702 (73%)]\tLoss: 1.887097, Accu: 31.25%\n",
      "Train Epoch: 7 [9600/12702 (76%)]\tLoss: 1.846348, Accu: 40.62%\n",
      "Train Epoch: 7 [9920/12702 (78%)]\tLoss: 1.853554, Accu: 31.25%\n",
      "Train Epoch: 7 [10240/12702 (81%)]\tLoss: 1.896685, Accu: 40.62%\n",
      "Train Epoch: 7 [10560/12702 (83%)]\tLoss: 2.062262, Accu: 37.50%\n",
      "Train Epoch: 7 [10880/12702 (86%)]\tLoss: 2.074084, Accu: 25.00%\n",
      "Train Epoch: 7 [11200/12702 (88%)]\tLoss: 2.017468, Accu: 28.12%\n",
      "Train Epoch: 7 [11520/12702 (91%)]\tLoss: 2.006555, Accu: 25.00%\n",
      "Train Epoch: 7 [11840/12702 (93%)]\tLoss: 2.082457, Accu: 15.62%\n",
      "Train Epoch: 7 [12160/12702 (96%)]\tLoss: 2.349013, Accu: 18.75%\n",
      "Train Epoch: 7 [12480/12702 (98%)]\tLoss: 2.034941, Accu: 31.25%\n",
      "\n",
      "Test set (1411 samples): Average loss: 1.9352, Accuracy: 34.23%\n",
      "\n",
      "Epoch 7 model saved!\n",
      "Train Epoch: 8 [320/12702 (3%)]\tLoss: 1.945519, Accu: 43.75%\n",
      "Train Epoch: 8 [640/12702 (5%)]\tLoss: 2.014047, Accu: 25.00%\n",
      "Train Epoch: 8 [960/12702 (8%)]\tLoss: 1.904109, Accu: 46.88%\n",
      "Train Epoch: 8 [1280/12702 (10%)]\tLoss: 1.858481, Accu: 34.38%\n",
      "Train Epoch: 8 [1600/12702 (13%)]\tLoss: 1.970551, Accu: 34.38%\n",
      "Train Epoch: 8 [1920/12702 (15%)]\tLoss: 1.785173, Accu: 31.25%\n",
      "Train Epoch: 8 [2240/12702 (18%)]\tLoss: 1.801320, Accu: 28.12%\n",
      "Train Epoch: 8 [2560/12702 (20%)]\tLoss: 1.934056, Accu: 15.62%\n",
      "Train Epoch: 8 [2880/12702 (23%)]\tLoss: 2.097858, Accu: 34.38%\n",
      "Train Epoch: 8 [3200/12702 (25%)]\tLoss: 1.872667, Accu: 25.00%\n",
      "Train Epoch: 8 [3520/12702 (28%)]\tLoss: 2.080956, Accu: 25.00%\n",
      "Train Epoch: 8 [3840/12702 (30%)]\tLoss: 1.951825, Accu: 28.12%\n",
      "Train Epoch: 8 [4160/12702 (33%)]\tLoss: 1.733862, Accu: 40.62%\n",
      "Train Epoch: 8 [4480/12702 (35%)]\tLoss: 1.951935, Accu: 21.88%\n",
      "Train Epoch: 8 [4800/12702 (38%)]\tLoss: 2.009232, Accu: 21.88%\n",
      "Train Epoch: 8 [5120/12702 (40%)]\tLoss: 1.933679, Accu: 31.25%\n",
      "Train Epoch: 8 [5440/12702 (43%)]\tLoss: 1.887805, Accu: 37.50%\n",
      "Train Epoch: 8 [5760/12702 (45%)]\tLoss: 1.910119, Accu: 18.75%\n",
      "Train Epoch: 8 [6080/12702 (48%)]\tLoss: 1.735632, Accu: 46.88%\n",
      "Train Epoch: 8 [6400/12702 (50%)]\tLoss: 2.164531, Accu: 31.25%\n",
      "Train Epoch: 8 [6720/12702 (53%)]\tLoss: 2.018630, Accu: 15.62%\n",
      "Train Epoch: 8 [7040/12702 (55%)]\tLoss: 1.808581, Accu: 31.25%\n",
      "Train Epoch: 8 [7360/12702 (58%)]\tLoss: 1.989025, Accu: 28.12%\n",
      "Train Epoch: 8 [7680/12702 (60%)]\tLoss: 1.676845, Accu: 53.12%\n",
      "Train Epoch: 8 [8000/12702 (63%)]\tLoss: 1.731045, Accu: 50.00%\n",
      "Train Epoch: 8 [8320/12702 (65%)]\tLoss: 2.355106, Accu: 12.50%\n",
      "Train Epoch: 8 [8640/12702 (68%)]\tLoss: 2.069155, Accu: 21.88%\n",
      "Train Epoch: 8 [8960/12702 (71%)]\tLoss: 1.867778, Accu: 25.00%\n",
      "Train Epoch: 8 [9280/12702 (73%)]\tLoss: 1.622627, Accu: 50.00%\n",
      "Train Epoch: 8 [9600/12702 (76%)]\tLoss: 1.814263, Accu: 40.62%\n",
      "Train Epoch: 8 [9920/12702 (78%)]\tLoss: 1.894222, Accu: 28.12%\n",
      "Train Epoch: 8 [10240/12702 (81%)]\tLoss: 1.923964, Accu: 21.88%\n",
      "Train Epoch: 8 [10560/12702 (83%)]\tLoss: 1.836576, Accu: 43.75%\n",
      "Train Epoch: 8 [10880/12702 (86%)]\tLoss: 1.845354, Accu: 37.50%\n",
      "Train Epoch: 8 [11200/12702 (88%)]\tLoss: 1.704825, Accu: 43.75%\n",
      "Train Epoch: 8 [11520/12702 (91%)]\tLoss: 1.828397, Accu: 43.75%\n",
      "Train Epoch: 8 [11840/12702 (93%)]\tLoss: 1.842213, Accu: 43.75%\n",
      "Train Epoch: 8 [12160/12702 (96%)]\tLoss: 1.849934, Accu: 34.38%\n",
      "Train Epoch: 8 [12480/12702 (98%)]\tLoss: 1.954197, Accu: 21.88%\n",
      "\n",
      "Test set (1411 samples): Average loss: 1.9325, Accuracy: 34.44%\n",
      "\n",
      "Epoch 8 model saved!\n",
      "Train Epoch: 9 [320/12702 (3%)]\tLoss: 1.879603, Accu: 31.25%\n",
      "Train Epoch: 9 [640/12702 (5%)]\tLoss: 1.799211, Accu: 37.50%\n",
      "Train Epoch: 9 [960/12702 (8%)]\tLoss: 1.667728, Accu: 37.50%\n",
      "Train Epoch: 9 [1280/12702 (10%)]\tLoss: 1.924891, Accu: 34.38%\n",
      "Train Epoch: 9 [1600/12702 (13%)]\tLoss: 1.831466, Accu: 40.62%\n",
      "Train Epoch: 9 [1920/12702 (15%)]\tLoss: 1.847370, Accu: 34.38%\n",
      "Train Epoch: 9 [2240/12702 (18%)]\tLoss: 1.986107, Accu: 34.38%\n",
      "Train Epoch: 9 [2560/12702 (20%)]\tLoss: 1.990791, Accu: 18.75%\n",
      "Train Epoch: 9 [2880/12702 (23%)]\tLoss: 1.920989, Accu: 34.38%\n",
      "Train Epoch: 9 [3200/12702 (25%)]\tLoss: 1.837264, Accu: 28.12%\n",
      "Train Epoch: 9 [3520/12702 (28%)]\tLoss: 1.721116, Accu: 46.88%\n",
      "Train Epoch: 9 [3840/12702 (30%)]\tLoss: 1.631879, Accu: 56.25%\n",
      "Train Epoch: 9 [4160/12702 (33%)]\tLoss: 1.820212, Accu: 25.00%\n",
      "Train Epoch: 9 [4480/12702 (35%)]\tLoss: 1.648402, Accu: 40.62%\n",
      "Train Epoch: 9 [4800/12702 (38%)]\tLoss: 1.702336, Accu: 40.62%\n",
      "Train Epoch: 9 [5120/12702 (40%)]\tLoss: 1.764628, Accu: 37.50%\n",
      "Train Epoch: 9 [5440/12702 (43%)]\tLoss: 1.699658, Accu: 40.62%\n",
      "Train Epoch: 9 [5760/12702 (45%)]\tLoss: 1.799738, Accu: 37.50%\n",
      "Train Epoch: 9 [6080/12702 (48%)]\tLoss: 2.003053, Accu: 31.25%\n",
      "Train Epoch: 9 [6400/12702 (50%)]\tLoss: 1.963457, Accu: 25.00%\n",
      "Train Epoch: 9 [6720/12702 (53%)]\tLoss: 1.749202, Accu: 46.88%\n",
      "Train Epoch: 9 [7040/12702 (55%)]\tLoss: 1.773031, Accu: 34.38%\n",
      "Train Epoch: 9 [7360/12702 (58%)]\tLoss: 1.841666, Accu: 21.88%\n",
      "Train Epoch: 9 [7680/12702 (60%)]\tLoss: 1.938845, Accu: 34.38%\n",
      "Train Epoch: 9 [8000/12702 (63%)]\tLoss: 1.789650, Accu: 34.38%\n",
      "Train Epoch: 9 [8320/12702 (65%)]\tLoss: 1.895092, Accu: 34.38%\n",
      "Train Epoch: 9 [8640/12702 (68%)]\tLoss: 1.683493, Accu: 43.75%\n",
      "Train Epoch: 9 [8960/12702 (71%)]\tLoss: 1.874431, Accu: 37.50%\n",
      "Train Epoch: 9 [9280/12702 (73%)]\tLoss: 1.843313, Accu: 37.50%\n",
      "Train Epoch: 9 [9600/12702 (76%)]\tLoss: 1.716977, Accu: 37.50%\n",
      "Train Epoch: 9 [9920/12702 (78%)]\tLoss: 1.828189, Accu: 34.38%\n",
      "Train Epoch: 9 [10240/12702 (81%)]\tLoss: 1.576689, Accu: 46.88%\n",
      "Train Epoch: 9 [10560/12702 (83%)]\tLoss: 1.636520, Accu: 46.88%\n",
      "Train Epoch: 9 [10880/12702 (86%)]\tLoss: 1.832854, Accu: 43.75%\n",
      "Train Epoch: 9 [11200/12702 (88%)]\tLoss: 1.885392, Accu: 37.50%\n",
      "Train Epoch: 9 [11520/12702 (91%)]\tLoss: 2.025092, Accu: 18.75%\n",
      "Train Epoch: 9 [11840/12702 (93%)]\tLoss: 1.917714, Accu: 25.00%\n",
      "Train Epoch: 9 [12160/12702 (96%)]\tLoss: 1.638395, Accu: 37.50%\n",
      "Train Epoch: 9 [12480/12702 (98%)]\tLoss: 1.841635, Accu: 34.38%\n",
      "\n",
      "Test set (1411 samples): Average loss: 1.9394, Accuracy: 32.53%\n",
      "\n",
      "Epoch 9 model saved!\n",
      "Train Epoch: 10 [320/12702 (3%)]\tLoss: 1.562016, Accu: 53.12%\n",
      "Train Epoch: 10 [640/12702 (5%)]\tLoss: 2.116406, Accu: 28.12%\n",
      "Train Epoch: 10 [960/12702 (8%)]\tLoss: 1.639261, Accu: 46.88%\n",
      "Train Epoch: 10 [1280/12702 (10%)]\tLoss: 1.722763, Accu: 43.75%\n",
      "Train Epoch: 10 [1600/12702 (13%)]\tLoss: 1.517604, Accu: 46.88%\n",
      "Train Epoch: 10 [1920/12702 (15%)]\tLoss: 1.707299, Accu: 43.75%\n",
      "Train Epoch: 10 [2240/12702 (18%)]\tLoss: 1.692489, Accu: 34.38%\n",
      "Train Epoch: 10 [2560/12702 (20%)]\tLoss: 1.771123, Accu: 37.50%\n",
      "Train Epoch: 10 [2880/12702 (23%)]\tLoss: 1.766980, Accu: 31.25%\n",
      "Train Epoch: 10 [3200/12702 (25%)]\tLoss: 1.627817, Accu: 46.88%\n",
      "Train Epoch: 10 [3520/12702 (28%)]\tLoss: 1.885114, Accu: 40.62%\n",
      "Train Epoch: 10 [3840/12702 (30%)]\tLoss: 2.192031, Accu: 28.12%\n",
      "Train Epoch: 10 [4160/12702 (33%)]\tLoss: 1.782892, Accu: 50.00%\n",
      "Train Epoch: 10 [4480/12702 (35%)]\tLoss: 1.651752, Accu: 40.62%\n",
      "Train Epoch: 10 [4800/12702 (38%)]\tLoss: 1.781702, Accu: 40.62%\n",
      "Train Epoch: 10 [5120/12702 (40%)]\tLoss: 1.738825, Accu: 40.62%\n",
      "Train Epoch: 10 [5440/12702 (43%)]\tLoss: 1.985035, Accu: 21.88%\n",
      "Train Epoch: 10 [5760/12702 (45%)]\tLoss: 1.652326, Accu: 40.62%\n",
      "Train Epoch: 10 [6080/12702 (48%)]\tLoss: 1.982639, Accu: 37.50%\n",
      "Train Epoch: 10 [6400/12702 (50%)]\tLoss: 1.819649, Accu: 34.38%\n",
      "Train Epoch: 10 [6720/12702 (53%)]\tLoss: 1.699213, Accu: 37.50%\n",
      "Train Epoch: 10 [7040/12702 (55%)]\tLoss: 1.524609, Accu: 43.75%\n",
      "Train Epoch: 10 [7360/12702 (58%)]\tLoss: 1.959403, Accu: 34.38%\n",
      "Train Epoch: 10 [7680/12702 (60%)]\tLoss: 1.718158, Accu: 31.25%\n",
      "Train Epoch: 10 [8000/12702 (63%)]\tLoss: 1.528162, Accu: 46.88%\n",
      "Train Epoch: 10 [8320/12702 (65%)]\tLoss: 1.885383, Accu: 28.12%\n",
      "Train Epoch: 10 [8640/12702 (68%)]\tLoss: 1.808264, Accu: 37.50%\n",
      "Train Epoch: 10 [8960/12702 (71%)]\tLoss: 1.756633, Accu: 31.25%\n",
      "Train Epoch: 10 [9280/12702 (73%)]\tLoss: 1.495981, Accu: 43.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [9600/12702 (76%)]\tLoss: 2.158154, Accu: 28.12%\n",
      "Train Epoch: 10 [9920/12702 (78%)]\tLoss: 1.777578, Accu: 40.62%\n",
      "Train Epoch: 10 [10240/12702 (81%)]\tLoss: 1.777323, Accu: 28.12%\n",
      "Train Epoch: 10 [10560/12702 (83%)]\tLoss: 1.718503, Accu: 43.75%\n",
      "Train Epoch: 10 [10880/12702 (86%)]\tLoss: 1.655703, Accu: 46.88%\n",
      "Train Epoch: 10 [11200/12702 (88%)]\tLoss: 2.017046, Accu: 21.88%\n",
      "Train Epoch: 10 [11520/12702 (91%)]\tLoss: 1.714610, Accu: 37.50%\n",
      "Train Epoch: 10 [11840/12702 (93%)]\tLoss: 1.676073, Accu: 37.50%\n",
      "Train Epoch: 10 [12160/12702 (96%)]\tLoss: 1.944494, Accu: 28.12%\n",
      "Train Epoch: 10 [12480/12702 (98%)]\tLoss: 1.935160, Accu: 25.00%\n",
      "\n",
      "Test set (1411 samples): Average loss: 1.9379, Accuracy: 33.24%\n",
      "\n",
      "Epoch 10 model saved!\n",
      "Train Epoch: 11 [320/12702 (3%)]\tLoss: 1.482299, Accu: 37.50%\n",
      "Train Epoch: 11 [640/12702 (5%)]\tLoss: 1.843349, Accu: 37.50%\n",
      "Train Epoch: 11 [960/12702 (8%)]\tLoss: 2.012330, Accu: 31.25%\n",
      "Train Epoch: 11 [1280/12702 (10%)]\tLoss: 1.500497, Accu: 43.75%\n",
      "Train Epoch: 11 [1600/12702 (13%)]\tLoss: 1.642430, Accu: 43.75%\n",
      "Train Epoch: 11 [1920/12702 (15%)]\tLoss: 1.726843, Accu: 43.75%\n",
      "Train Epoch: 11 [2240/12702 (18%)]\tLoss: 1.548213, Accu: 37.50%\n",
      "Train Epoch: 11 [2560/12702 (20%)]\tLoss: 1.412382, Accu: 56.25%\n",
      "Train Epoch: 11 [2880/12702 (23%)]\tLoss: 1.835747, Accu: 43.75%\n",
      "Train Epoch: 11 [3200/12702 (25%)]\tLoss: 1.621685, Accu: 46.88%\n",
      "Train Epoch: 11 [3520/12702 (28%)]\tLoss: 1.508182, Accu: 56.25%\n",
      "Train Epoch: 11 [3840/12702 (30%)]\tLoss: 1.711054, Accu: 37.50%\n",
      "Train Epoch: 11 [4160/12702 (33%)]\tLoss: 1.462336, Accu: 56.25%\n",
      "Train Epoch: 11 [4480/12702 (35%)]\tLoss: 1.545777, Accu: 50.00%\n",
      "Train Epoch: 11 [4800/12702 (38%)]\tLoss: 1.538408, Accu: 46.88%\n",
      "Train Epoch: 11 [5120/12702 (40%)]\tLoss: 1.776257, Accu: 37.50%\n",
      "Train Epoch: 11 [5440/12702 (43%)]\tLoss: 1.466815, Accu: 46.88%\n",
      "Train Epoch: 11 [5760/12702 (45%)]\tLoss: 1.671456, Accu: 34.38%\n",
      "Train Epoch: 11 [6080/12702 (48%)]\tLoss: 1.640537, Accu: 43.75%\n",
      "Train Epoch: 11 [6400/12702 (50%)]\tLoss: 1.714041, Accu: 28.12%\n",
      "Train Epoch: 11 [6720/12702 (53%)]\tLoss: 1.528618, Accu: 50.00%\n",
      "Train Epoch: 11 [7040/12702 (55%)]\tLoss: 1.712990, Accu: 37.50%\n",
      "Train Epoch: 11 [7360/12702 (58%)]\tLoss: 1.548149, Accu: 37.50%\n",
      "Train Epoch: 11 [7680/12702 (60%)]\tLoss: 1.455724, Accu: 46.88%\n",
      "Train Epoch: 11 [8000/12702 (63%)]\tLoss: 1.742931, Accu: 43.75%\n",
      "Train Epoch: 11 [8320/12702 (65%)]\tLoss: 1.688640, Accu: 53.12%\n",
      "Train Epoch: 11 [8640/12702 (68%)]\tLoss: 1.616109, Accu: 50.00%\n",
      "Train Epoch: 11 [8960/12702 (71%)]\tLoss: 1.953542, Accu: 34.38%\n",
      "Train Epoch: 11 [9280/12702 (73%)]\tLoss: 2.002367, Accu: 21.88%\n",
      "Train Epoch: 11 [9600/12702 (76%)]\tLoss: 1.486594, Accu: 56.25%\n",
      "Train Epoch: 11 [9920/12702 (78%)]\tLoss: 1.758978, Accu: 43.75%\n",
      "Train Epoch: 11 [10240/12702 (81%)]\tLoss: 1.573504, Accu: 43.75%\n",
      "Train Epoch: 11 [10560/12702 (83%)]\tLoss: 1.366570, Accu: 59.38%\n",
      "Train Epoch: 11 [10880/12702 (86%)]\tLoss: 1.457781, Accu: 50.00%\n",
      "Train Epoch: 11 [11200/12702 (88%)]\tLoss: 1.712108, Accu: 40.62%\n",
      "Train Epoch: 11 [11520/12702 (91%)]\tLoss: 1.754419, Accu: 37.50%\n",
      "Train Epoch: 11 [11840/12702 (93%)]\tLoss: 1.730418, Accu: 31.25%\n",
      "Train Epoch: 11 [12160/12702 (96%)]\tLoss: 1.339578, Accu: 62.50%\n",
      "Train Epoch: 11 [12480/12702 (98%)]\tLoss: 1.842492, Accu: 43.75%\n",
      "\n",
      "Test set (1411 samples): Average loss: 1.9678, Accuracy: 32.39%\n",
      "\n",
      "Epoch 11 model saved!\n",
      "Train Epoch: 12 [320/12702 (3%)]\tLoss: 1.741188, Accu: 34.38%\n",
      "Train Epoch: 12 [640/12702 (5%)]\tLoss: 1.674061, Accu: 46.88%\n",
      "Train Epoch: 12 [960/12702 (8%)]\tLoss: 1.493900, Accu: 37.50%\n",
      "Train Epoch: 12 [1280/12702 (10%)]\tLoss: 1.338677, Accu: 56.25%\n",
      "Train Epoch: 12 [1600/12702 (13%)]\tLoss: 1.608387, Accu: 43.75%\n",
      "Train Epoch: 12 [1920/12702 (15%)]\tLoss: 1.603449, Accu: 34.38%\n",
      "Train Epoch: 12 [2240/12702 (18%)]\tLoss: 1.649885, Accu: 50.00%\n",
      "Train Epoch: 12 [2560/12702 (20%)]\tLoss: 1.378075, Accu: 53.12%\n",
      "Train Epoch: 12 [2880/12702 (23%)]\tLoss: 1.754640, Accu: 46.88%\n",
      "Train Epoch: 12 [3200/12702 (25%)]\tLoss: 1.774706, Accu: 37.50%\n",
      "Train Epoch: 12 [3520/12702 (28%)]\tLoss: 1.752102, Accu: 28.12%\n",
      "Train Epoch: 12 [3840/12702 (30%)]\tLoss: 1.557151, Accu: 46.88%\n",
      "Train Epoch: 12 [4160/12702 (33%)]\tLoss: 1.555543, Accu: 50.00%\n",
      "Train Epoch: 12 [4480/12702 (35%)]\tLoss: 1.168645, Accu: 62.50%\n",
      "Train Epoch: 12 [4800/12702 (38%)]\tLoss: 1.598304, Accu: 46.88%\n",
      "Train Epoch: 12 [5120/12702 (40%)]\tLoss: 1.522594, Accu: 40.62%\n",
      "Train Epoch: 12 [5440/12702 (43%)]\tLoss: 1.573389, Accu: 46.88%\n",
      "Train Epoch: 12 [5760/12702 (45%)]\tLoss: 1.482386, Accu: 46.88%\n",
      "Train Epoch: 12 [6080/12702 (48%)]\tLoss: 1.519917, Accu: 50.00%\n",
      "Train Epoch: 12 [6400/12702 (50%)]\tLoss: 1.850040, Accu: 43.75%\n",
      "Train Epoch: 12 [6720/12702 (53%)]\tLoss: 1.555518, Accu: 46.88%\n",
      "Train Epoch: 12 [7040/12702 (55%)]\tLoss: 1.453016, Accu: 56.25%\n",
      "Train Epoch: 12 [7360/12702 (58%)]\tLoss: 1.415275, Accu: 50.00%\n",
      "Train Epoch: 12 [7680/12702 (60%)]\tLoss: 1.917877, Accu: 34.38%\n",
      "Train Epoch: 12 [8000/12702 (63%)]\tLoss: 1.729438, Accu: 31.25%\n",
      "Train Epoch: 12 [8320/12702 (65%)]\tLoss: 1.560007, Accu: 37.50%\n",
      "Train Epoch: 12 [8640/12702 (68%)]\tLoss: 1.460258, Accu: 40.62%\n",
      "Train Epoch: 12 [8960/12702 (71%)]\tLoss: 1.475990, Accu: 40.62%\n",
      "Train Epoch: 12 [9280/12702 (73%)]\tLoss: 1.386912, Accu: 59.38%\n",
      "Train Epoch: 12 [9600/12702 (76%)]\tLoss: 1.493847, Accu: 43.75%\n",
      "Train Epoch: 12 [9920/12702 (78%)]\tLoss: 1.548603, Accu: 46.88%\n",
      "Train Epoch: 12 [10240/12702 (81%)]\tLoss: 1.611367, Accu: 46.88%\n",
      "Train Epoch: 12 [10560/12702 (83%)]\tLoss: 1.551321, Accu: 53.12%\n",
      "Train Epoch: 12 [10880/12702 (86%)]\tLoss: 1.613057, Accu: 46.88%\n",
      "Train Epoch: 12 [11200/12702 (88%)]\tLoss: 1.910482, Accu: 34.38%\n",
      "Train Epoch: 12 [11520/12702 (91%)]\tLoss: 1.921897, Accu: 40.62%\n",
      "Train Epoch: 12 [11840/12702 (93%)]\tLoss: 1.512084, Accu: 43.75%\n",
      "Train Epoch: 12 [12160/12702 (96%)]\tLoss: 1.679853, Accu: 37.50%\n",
      "Train Epoch: 12 [12480/12702 (98%)]\tLoss: 1.297659, Accu: 56.25%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.0101, Accuracy: 32.67%\n",
      "\n",
      "Epoch 12 model saved!\n",
      "Train Epoch: 13 [320/12702 (3%)]\tLoss: 1.596758, Accu: 46.88%\n",
      "Train Epoch: 13 [640/12702 (5%)]\tLoss: 1.452202, Accu: 50.00%\n",
      "Train Epoch: 13 [960/12702 (8%)]\tLoss: 1.281932, Accu: 65.62%\n",
      "Train Epoch: 13 [1280/12702 (10%)]\tLoss: 1.616847, Accu: 46.88%\n",
      "Train Epoch: 13 [1600/12702 (13%)]\tLoss: 1.750984, Accu: 40.62%\n",
      "Train Epoch: 13 [1920/12702 (15%)]\tLoss: 1.399536, Accu: 50.00%\n",
      "Train Epoch: 13 [2240/12702 (18%)]\tLoss: 1.723785, Accu: 34.38%\n",
      "Train Epoch: 13 [2560/12702 (20%)]\tLoss: 1.533720, Accu: 43.75%\n",
      "Train Epoch: 13 [2880/12702 (23%)]\tLoss: 1.664559, Accu: 28.12%\n",
      "Train Epoch: 13 [3200/12702 (25%)]\tLoss: 1.668049, Accu: 31.25%\n",
      "Train Epoch: 13 [3520/12702 (28%)]\tLoss: 1.438256, Accu: 53.12%\n",
      "Train Epoch: 13 [3840/12702 (30%)]\tLoss: 1.631763, Accu: 43.75%\n",
      "Train Epoch: 13 [4160/12702 (33%)]\tLoss: 1.738345, Accu: 37.50%\n",
      "Train Epoch: 13 [4480/12702 (35%)]\tLoss: 1.379066, Accu: 46.88%\n",
      "Train Epoch: 13 [4800/12702 (38%)]\tLoss: 1.641832, Accu: 43.75%\n",
      "Train Epoch: 13 [5120/12702 (40%)]\tLoss: 1.545550, Accu: 43.75%\n",
      "Train Epoch: 13 [5440/12702 (43%)]\tLoss: 1.540080, Accu: 50.00%\n",
      "Train Epoch: 13 [5760/12702 (45%)]\tLoss: 1.468571, Accu: 40.62%\n",
      "Train Epoch: 13 [6080/12702 (48%)]\tLoss: 1.330083, Accu: 59.38%\n",
      "Train Epoch: 13 [6400/12702 (50%)]\tLoss: 1.583704, Accu: 43.75%\n",
      "Train Epoch: 13 [6720/12702 (53%)]\tLoss: 1.392036, Accu: 62.50%\n",
      "Train Epoch: 13 [7040/12702 (55%)]\tLoss: 1.712188, Accu: 37.50%\n",
      "Train Epoch: 13 [7360/12702 (58%)]\tLoss: 1.742776, Accu: 40.62%\n",
      "Train Epoch: 13 [7680/12702 (60%)]\tLoss: 1.351597, Accu: 59.38%\n",
      "Train Epoch: 13 [8000/12702 (63%)]\tLoss: 1.521347, Accu: 53.12%\n",
      "Train Epoch: 13 [8320/12702 (65%)]\tLoss: 1.406887, Accu: 59.38%\n",
      "Train Epoch: 13 [8640/12702 (68%)]\tLoss: 1.217652, Accu: 59.38%\n",
      "Train Epoch: 13 [8960/12702 (71%)]\tLoss: 1.634233, Accu: 46.88%\n",
      "Train Epoch: 13 [9280/12702 (73%)]\tLoss: 1.657560, Accu: 34.38%\n",
      "Train Epoch: 13 [9600/12702 (76%)]\tLoss: 1.153899, Accu: 59.38%\n",
      "Train Epoch: 13 [9920/12702 (78%)]\tLoss: 1.630358, Accu: 43.75%\n",
      "Train Epoch: 13 [10240/12702 (81%)]\tLoss: 1.310698, Accu: 46.88%\n",
      "Train Epoch: 13 [10560/12702 (83%)]\tLoss: 1.662910, Accu: 31.25%\n",
      "Train Epoch: 13 [10880/12702 (86%)]\tLoss: 1.675531, Accu: 59.38%\n",
      "Train Epoch: 13 [11200/12702 (88%)]\tLoss: 1.443212, Accu: 53.12%\n",
      "Train Epoch: 13 [11520/12702 (91%)]\tLoss: 1.505218, Accu: 56.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [11840/12702 (93%)]\tLoss: 1.477202, Accu: 37.50%\n",
      "Train Epoch: 13 [12160/12702 (96%)]\tLoss: 1.510149, Accu: 56.25%\n",
      "Train Epoch: 13 [12480/12702 (98%)]\tLoss: 1.575286, Accu: 40.62%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.0873, Accuracy: 28.84%\n",
      "\n",
      "Epoch 13 model saved!\n",
      "Train Epoch: 14 [320/12702 (3%)]\tLoss: 1.628674, Accu: 40.62%\n",
      "Train Epoch: 14 [640/12702 (5%)]\tLoss: 1.772729, Accu: 50.00%\n",
      "Train Epoch: 14 [960/12702 (8%)]\tLoss: 1.890725, Accu: 31.25%\n",
      "Train Epoch: 14 [1280/12702 (10%)]\tLoss: 1.295313, Accu: 56.25%\n",
      "Train Epoch: 14 [1600/12702 (13%)]\tLoss: 1.516147, Accu: 50.00%\n",
      "Train Epoch: 14 [1920/12702 (15%)]\tLoss: 1.770723, Accu: 31.25%\n",
      "Train Epoch: 14 [2240/12702 (18%)]\tLoss: 1.584349, Accu: 46.88%\n",
      "Train Epoch: 14 [2560/12702 (20%)]\tLoss: 1.536995, Accu: 53.12%\n",
      "Train Epoch: 14 [2880/12702 (23%)]\tLoss: 1.416406, Accu: 50.00%\n",
      "Train Epoch: 14 [3200/12702 (25%)]\tLoss: 1.425943, Accu: 50.00%\n",
      "Train Epoch: 14 [3520/12702 (28%)]\tLoss: 1.251592, Accu: 56.25%\n",
      "Train Epoch: 14 [3840/12702 (30%)]\tLoss: 1.492042, Accu: 56.25%\n",
      "Train Epoch: 14 [4160/12702 (33%)]\tLoss: 1.352056, Accu: 62.50%\n",
      "Train Epoch: 14 [4480/12702 (35%)]\tLoss: 1.404526, Accu: 53.12%\n",
      "Train Epoch: 14 [4800/12702 (38%)]\tLoss: 1.413895, Accu: 40.62%\n",
      "Train Epoch: 14 [5120/12702 (40%)]\tLoss: 1.245157, Accu: 62.50%\n",
      "Train Epoch: 14 [5440/12702 (43%)]\tLoss: 1.543977, Accu: 50.00%\n",
      "Train Epoch: 14 [5760/12702 (45%)]\tLoss: 1.536382, Accu: 53.12%\n",
      "Train Epoch: 14 [6080/12702 (48%)]\tLoss: 1.497766, Accu: 56.25%\n",
      "Train Epoch: 14 [6400/12702 (50%)]\tLoss: 1.381137, Accu: 40.62%\n",
      "Train Epoch: 14 [6720/12702 (53%)]\tLoss: 1.615141, Accu: 46.88%\n",
      "Train Epoch: 14 [7040/12702 (55%)]\tLoss: 1.304604, Accu: 53.12%\n",
      "Train Epoch: 14 [7360/12702 (58%)]\tLoss: 1.624449, Accu: 37.50%\n",
      "Train Epoch: 14 [7680/12702 (60%)]\tLoss: 1.757229, Accu: 40.62%\n",
      "Train Epoch: 14 [8000/12702 (63%)]\tLoss: 1.290976, Accu: 56.25%\n",
      "Train Epoch: 14 [8320/12702 (65%)]\tLoss: 1.324143, Accu: 46.88%\n",
      "Train Epoch: 14 [8640/12702 (68%)]\tLoss: 1.553372, Accu: 34.38%\n",
      "Train Epoch: 14 [8960/12702 (71%)]\tLoss: 1.505223, Accu: 46.88%\n",
      "Train Epoch: 14 [9280/12702 (73%)]\tLoss: 1.336149, Accu: 50.00%\n",
      "Train Epoch: 14 [9600/12702 (76%)]\tLoss: 1.733356, Accu: 37.50%\n",
      "Train Epoch: 14 [9920/12702 (78%)]\tLoss: 1.408321, Accu: 50.00%\n",
      "Train Epoch: 14 [10240/12702 (81%)]\tLoss: 1.625742, Accu: 43.75%\n",
      "Train Epoch: 14 [10560/12702 (83%)]\tLoss: 1.538865, Accu: 31.25%\n",
      "Train Epoch: 14 [10880/12702 (86%)]\tLoss: 1.218497, Accu: 65.62%\n",
      "Train Epoch: 14 [11200/12702 (88%)]\tLoss: 1.502571, Accu: 53.12%\n",
      "Train Epoch: 14 [11520/12702 (91%)]\tLoss: 1.399813, Accu: 46.88%\n",
      "Train Epoch: 14 [11840/12702 (93%)]\tLoss: 1.447791, Accu: 50.00%\n",
      "Train Epoch: 14 [12160/12702 (96%)]\tLoss: 1.578210, Accu: 34.38%\n",
      "Train Epoch: 14 [12480/12702 (98%)]\tLoss: 1.778232, Accu: 40.62%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.1115, Accuracy: 31.75%\n",
      "\n",
      "Epoch 14 model saved!\n",
      "Train Epoch: 15 [320/12702 (3%)]\tLoss: 1.402302, Accu: 53.12%\n",
      "Train Epoch: 15 [640/12702 (5%)]\tLoss: 1.501781, Accu: 37.50%\n",
      "Train Epoch: 15 [960/12702 (8%)]\tLoss: 1.165677, Accu: 53.12%\n",
      "Train Epoch: 15 [1280/12702 (10%)]\tLoss: 1.693197, Accu: 43.75%\n",
      "Train Epoch: 15 [1600/12702 (13%)]\tLoss: 1.248819, Accu: 56.25%\n",
      "Train Epoch: 15 [1920/12702 (15%)]\tLoss: 1.372679, Accu: 56.25%\n",
      "Train Epoch: 15 [2240/12702 (18%)]\tLoss: 1.290182, Accu: 53.12%\n",
      "Train Epoch: 15 [2560/12702 (20%)]\tLoss: 1.407626, Accu: 50.00%\n",
      "Train Epoch: 15 [2880/12702 (23%)]\tLoss: 1.293050, Accu: 50.00%\n",
      "Train Epoch: 15 [3200/12702 (25%)]\tLoss: 1.381791, Accu: 50.00%\n",
      "Train Epoch: 15 [3520/12702 (28%)]\tLoss: 1.276723, Accu: 62.50%\n",
      "Train Epoch: 15 [3840/12702 (30%)]\tLoss: 1.499033, Accu: 40.62%\n",
      "Train Epoch: 15 [4160/12702 (33%)]\tLoss: 1.253570, Accu: 65.62%\n",
      "Train Epoch: 15 [4480/12702 (35%)]\tLoss: 1.325810, Accu: 71.88%\n",
      "Train Epoch: 15 [4800/12702 (38%)]\tLoss: 1.426854, Accu: 46.88%\n",
      "Train Epoch: 15 [5120/12702 (40%)]\tLoss: 1.153983, Accu: 71.88%\n",
      "Train Epoch: 15 [5440/12702 (43%)]\tLoss: 1.782188, Accu: 37.50%\n",
      "Train Epoch: 15 [5760/12702 (45%)]\tLoss: 1.612980, Accu: 46.88%\n",
      "Train Epoch: 15 [6080/12702 (48%)]\tLoss: 1.215591, Accu: 62.50%\n",
      "Train Epoch: 15 [6400/12702 (50%)]\tLoss: 1.430292, Accu: 50.00%\n",
      "Train Epoch: 15 [6720/12702 (53%)]\tLoss: 1.286515, Accu: 50.00%\n",
      "Train Epoch: 15 [7040/12702 (55%)]\tLoss: 1.560953, Accu: 53.12%\n",
      "Train Epoch: 15 [7360/12702 (58%)]\tLoss: 1.455505, Accu: 46.88%\n",
      "Train Epoch: 15 [7680/12702 (60%)]\tLoss: 1.456932, Accu: 59.38%\n",
      "Train Epoch: 15 [8000/12702 (63%)]\tLoss: 0.968073, Accu: 59.38%\n",
      "Train Epoch: 15 [8320/12702 (65%)]\tLoss: 1.423957, Accu: 50.00%\n",
      "Train Epoch: 15 [8640/12702 (68%)]\tLoss: 1.452515, Accu: 53.12%\n",
      "Train Epoch: 15 [8960/12702 (71%)]\tLoss: 1.456420, Accu: 50.00%\n",
      "Train Epoch: 15 [9280/12702 (73%)]\tLoss: 1.158283, Accu: 62.50%\n",
      "Train Epoch: 15 [9600/12702 (76%)]\tLoss: 1.446743, Accu: 43.75%\n",
      "Train Epoch: 15 [9920/12702 (78%)]\tLoss: 1.271761, Accu: 62.50%\n",
      "Train Epoch: 15 [10240/12702 (81%)]\tLoss: 1.475131, Accu: 46.88%\n",
      "Train Epoch: 15 [10560/12702 (83%)]\tLoss: 1.220714, Accu: 59.38%\n",
      "Train Epoch: 15 [10880/12702 (86%)]\tLoss: 1.482667, Accu: 53.12%\n",
      "Train Epoch: 15 [11200/12702 (88%)]\tLoss: 1.726808, Accu: 34.38%\n",
      "Train Epoch: 15 [11520/12702 (91%)]\tLoss: 1.615514, Accu: 40.62%\n",
      "Train Epoch: 15 [11840/12702 (93%)]\tLoss: 1.447377, Accu: 37.50%\n",
      "Train Epoch: 15 [12160/12702 (96%)]\tLoss: 1.406883, Accu: 40.62%\n",
      "Train Epoch: 15 [12480/12702 (98%)]\tLoss: 1.410766, Accu: 59.38%\n",
      "\n",
      "Test set (1411 samples): Average loss: 2.1580, Accuracy: 31.54%\n",
      "\n",
      "Epoch 15 model saved!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
